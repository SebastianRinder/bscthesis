Matrices and constants are noted as capital letters, and vectors and scalars as lower case letters. Vectors are assumed as column vectors. The first dimension of a matrix indicates its row number, the second dimension its column number.\\
\\
\begin{tabular}{l l}
    \underline{Symbol} & \underline{Meaning}\\
    $S$ & Matrix of states\\
    $A$ & Matrix of actions\\
    $p$ & state transitioning probabilitiy\\
    $p_0$ & probabilitiy of starting in state $s_0$\\
    $r$ & immediate reward\\
    $\bar{r}$ & cumulative reward, sum of all rewards from one trajectory\\
    $M$ & number of initial sample points before starting the Bayesian optimization\\
    $N$ & number of total Bayesian optimization steps\\
    $n$ & number of training points present\\
    $n_*$ & number of sample test points\\
    $d$ & number of dimensions in the problem\\
    $x$ & training point vector of length $d$\\
    $x_*$ & test point vector of length $d$\\
    $X$ & $n \times d$ matrix of $n$ points $x^{\top}$\\
    $X_*$ & $n_* \times d$ matrix of $n_*$ test points $x^{\top}_*$\\
    $y$ & vector of $n$ evaluated objective function values\\
    $K(X,X) = K$ & $n \times n$ covariance matrix\\
    $K(X,X_*) = K_*$ & $n \times n_*$ covariance between training and test points\\
    $K(X_*,X) = K_*^\top$ & same as $K(X,X_*)^{\top}$\\
    $K(X_*,X_*) = K_{**}$ & $n_* \times n_*$ covariance matrix\\
    $\circ$ & Hadamard product, element-wise product\\
    diag($V$) & returns the diagonal elements of the square matrix $V$ as a vector\\
\end{tabular}
