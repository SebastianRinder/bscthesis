\begin{abstract}[1]
    In this thesis we investigate the performance of two trajectory kernels used by Bayesian optimization to solve robotic reinforcement learning tasks. Furthermore, we contribute a trajectory kernel to a Bayesian optimization algorithm, which optimizes over a local search space. Bayesian optimization has proven to be particularly effective in the area of reinforcement learning tasks in recent years \cite{wilson2014using}, but also has some disadvantages. When it comes to higher dimensional problems, Bayesian optimization does not scale well due to the huge search space that needs to be optimized globally. In addition, commonly used standard kernels in Bayesian optimization only detect similarities in policy parameters, but not in behaviour patterns. For this reason, we implement trajectory kernels to the Gaussian process used by Bayesian optimization. These kernels exploit trajectory data generated by the reinforcement learning agent, to derive a more precise measure than policy parameter values.\\
    To compensate for the global nature of Bayesian optimization, we use the algorithm proposed by \cite{akrour2017local}, which restricts the search space to a local area. In this thesis we show that restricting the search space enhances the learning performance in the reinforcement learning tasks of Cart Pole, Acrobot and Mountain Car. Based on our results, trajectory kernels also perform slightly better at their peak performance level compared to the standard kernels squared exponential and Matérn 5/2. While one of the trajectory kernels is contributed by us, the other one is adapted from \cite{wilson2014using}.
\end{abstract}



% \selectlanguage{ngerman} % select german language
% \begin{abstract}[2]
%     Das Ziel im bestärkten Lernen ist das Finden einer Strategie, welche die erhaltene Belohnung eines Agenten maximiert. Da der Suchraum für mögliche Strategien sehr groß sein kann, verwenden wir Bayesian optimization, um die Anzahl der Evaluierungen durch den Agenten zu minimieren. Das hat den Vorteil, dass zeit- und kostenaufwändige Abläufe, wie beispielsweise das Bewegen eines Roboterarms, reduziert werden.
%     Die Effektivität der Suche wird maßgeblich von der Wahl des Kernels beeinflusst.
%     Standardkernel in der Bayesian optimization vergleichen die Parameter von Strategien um eine Vorhersage über bisher nicht evaluierte Strategien zu treffen.
%
%     Der Trajectorykernel vergleicht statt der Parameter, die aus den jeweiligen Strategien resultierenden Verhaltensweisen. Dadurch werden unterschiedliche Strategien mit ähnlichem Resultat von der Suche weniger priorisiert.
%
%     Wir zeigen die Überlegenheit des verhaltensbasierten Kernels gegenüber dem parameterbasierten anhand von Robotersteruerungssimulationen.
% \end{abstract}
% \selectlanguage{english} % reset to english language
