\begin{thebibliography}{1}

\bibitem{wilson2014using}
A.~Wilson, A.~Fern, and P.~Tadepalli, ``Using trajectory data to improve
  bayesian optimization for reinforcement learning,'' {\em The Journal of
  Machine Learning Research}, vol.~15, no.~1, pp.~253--282, 2014.

\bibitem{rasmussen2006gaussian}
C.~E. Rasmussen and C.~K. Williams, {\em Gaussian processes for machine
  learning}, vol.~1.
\newblock MIT press Cambridge, 2006.

\bibitem{brochu2010tutorial}
E.~Brochu, V.~M. Cora, and N.~De~Freitas, ``A tutorial on bayesian optimization
  of expensive cost functions, with application to active user modeling and
  hierarchical reinforcement learning,'' {\em arXiv preprint arXiv:1012.2599},
  2010.

\bibitem{Kupcsik_AI_conditionallyaccepted}
A.~Kupcsik, M.~Deisenroth, J.~Peters, L.~Ai~Poh, V.~Vadakkepat, and G.~Neumann,
  ``Model-based contextual policy search for data-efficient generalization of
  robot skills,'' conditionally accepted.

\bibitem{Muelling_BC_accepted}
K.~Muelling, A.~Boularias, B.~Mohler, B.~Schoelkopf, and J.~Peters, ``Learning
  strategies in table tennis using inverse reinforcement learning,'' accepted.

\bibitem{dann14a}
C.~Dann, G.~Neumann, and J.~Peters, ``Policy evaluation with temporal
  differences: A survey and comparison,'' no.~March, pp.~809--883, 2014.

\bibitem{Meyer_JNER_2013}
T.~Meyer, J.~Peters, T.~Zander, B.~Schoelkopf, and M.~Grosse-Wentrup,
  ``Predicting motor learning performance from electroencephalographic data,''
  no.~1, 2014.

\bibitem{Bocsi_AR_2014}
B.~Bocsi, L.~Csato, and J.~Peters, ``Indirect robot model learning for tracking
  control,'' 2014.

\bibitem{BenAmor_AR_2014}
H.~Ben~Amor, A.~Saxena, N.~Hudson, and J.~Peters, ``Special issue on autonomous
  grasping and manipulation,'' 2014.

\end{thebibliography}
