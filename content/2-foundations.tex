\chapter{Foundations}
\label{chap:2}
%

- Bayesian optimization

- Global optimization

- Local optimization

- Gaussian Process Regression

- Expected Improvement

- Thompson Sampling

- Standard kernel

- Trajectory kernel

Bayesian optimization



Bayesian optimization is a powerful strategy for finding the extrema of objective
functions that are expensive to evaluate. It is applicable in situations where one
does not have a closed-form expression for the objective function, but where one
can obtain observations of this function at sampled values. It
is particularly useful when these evaluations are costly, when one does not have
access to derivatives, or when the problem at hand is non-convex.
Bayesian optimization techniques are some of the most efficient approaches
in terms of the number of function evaluations required (see, e.g. [Močkus, 1994,
Jones et al., 1998, Streltsov and Vakili, 1999, Jones, 2001, Sasena, 2002]). Much
of the efficiency stems from the ability of Bayesian optimization to incorporate
prior belief about the problem to help direct the sampling, and to trade off
exploration and exploitation of the search space. It is called Bayesian because
it uses the famous “Bayes’ theorem”, which states (simplifying somewhat) that
the posterior probability of a model (or theory, or hypothesis) M given evidence (or data, or observations) E is proportional to the likelihood of E given
M multiplied by the prior probability of M :
$$P(M|E)\propto P(E|M)P(M).$$



The posterior captures our updated beliefs about the unknown objective func-
tion. One may also interpret this step of Bayesian optimization as estimating
the objective function with a surrogate function (also called a response sur-
face), described formally in 2.1 with the posterior mean function of a Gaussian
process.
To sample efficiently, Bayesian optimization uses an acquisition function to
determine the next location x t+1 elem A to sample. The decision represents an
automatic trade-off between exploration (where the objective function is very
uncertain) and exploitation (trying values of x where the objective function is
expected to be high). This optimization technique has the nice property that it
aims to minimize the number of objective function evaluations. Moreover, it is
likely to do well even in settings where the objective function has multiple local
maxima.


Figure 1D BO


Gaussian process

In this book we will be concerned with supervised learning, which is the problem of learning input-output mappings from empirical data (the training dataset). Depending on the characteristics of the output, this problem is known as either regression, for continuous outputs, or classification, when outputs are discrete. An example of a regression problem can be found in robotics, where we wish to learn the inverse dynamics of a robot arm. Here the task is to map from the state of the arm (given by the positions, velocities and accelerations of the joints) to the corresponding torques on the joints. Such a model can then be used to compute the torques needed to move the arm along a given trajectory.

In general we denote the input as x, and the output (or target) as y. The input is usually represented as a vector x as there are in general many input variables—in the handwritten digit recognition example one may have a 256-dimensional input obtained from a raster scan of a 16 × 16 image, and in the robot arm example there are three input measurements for each joint in the arm. The target y may either be continuous (as in the regression case) or discrete (as in the classification case). We have a dataset D of n observations, D = {(x i , y i )|i = 1, . . . , n}. Given this training data we wish to make predictions for new inputs x* that we have not seen in the training set. Thus it is clear that the problem at hand is inductive; we need to move from the finite training data D to a function f that makes predictions for all possible input values.
